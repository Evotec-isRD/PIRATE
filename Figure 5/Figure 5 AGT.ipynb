{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d6733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import json\n",
    "import torch\n",
    "from scipy.stats import spearmanr\n",
    "import catboost\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForTokenClassification\n",
    "import torch.nn.functional as F\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a681811-7394-49b3-bc4d-9c4ceda18b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please update this path to the location of your local DR-BERT checkpoint file. \n",
    "checkpoint = r\"C:\\Users\\GRICHARDSON\\OneDrive - Evotec\\Desktop\\crystallization_deletion_tool\\DR-BERT-final\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "bert_model = AutoModelForTokenClassification.from_pretrained(checkpoint)\n",
    "bert_model = bert_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df00c7e-5c53-4b82-a47f-a3911c65c63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafiles = [\"CAID-agt_wt\", \"CAID-agt_G82E\", \"CAID-agt_D183N\", \"CAID-agt_K209R\", \"CAID-agt_S218L\",\n",
    "             \"CAID-agt_F152I\", \"CAID-agt_G156R\", \"CAID-agt_G161R\", \"CAID-agt_C173Y\", \"CAID-agt_S187F\",\n",
    "             \"CAID-agt_G41R\", \"CAID-agt_G41V\", \"CAID-agt_A112D\", \"CAID-agt_R233C\", \"CAID-agt_R233H\", \n",
    "             \"CAID-agt_V336D\"]\n",
    "models = [\"ESpritz N\", \"ESpritz X\", \"ESpritz D\", \"DisEMBL 465\", \"DisEMBL HL\", \"IUPred3\", \"pyHCA-dis\", \"DisoMine\", \"RONN\", \n",
    "          \"IsUnstruct\", \"VSL2\", \"MobiDB-lite\", \"SPOT-Disorder-Single\", \"AIUPred\", \"flDPnn\", \"flDPlr\", \"AUCpreD no_profile\",\n",
    "          \"AUCpreD profile\", \"DeepIDP-2L\", \"SETH_0\", \"DisoPred\", \"PreDisorder\", \"IDP-Fusion\", \"PredIDR long\", \"PredIDR short\",\n",
    "          \"SPOT-Disorder\", \"APOD\", \"s2D-2\", \"DISOPRED3 diso\", \"DisPredict3\", \"DisPredict2\", \"rawMSA\", \"SPOT-Disorder2\", \"SETH_1\"]\n",
    "trypsin_activities = [0, 0, 0, 1, 2, 0.5, 4, 4, 4, 1, 4, 3, 3, 1, 1, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1498cde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def afsm12_encode_data(data, input_size):\n",
    "    \"\"\"\n",
    "    Takes in fasta sequence and returns encoded/padded data\n",
    "    \"\"\"\n",
    "    residue_dictionary = {\"A\": 1, \"E\": 2, \"L\": 3, \"M\": 4, \"C\": 5, \"D\": 6, \"F\": 7, \"G\": 8,\n",
    "                          \"H\": 9, \"K\":10, \"N\": 11, \"P\": 12, \"Q\": 13, \"R\": 14, \"S\": 15,\n",
    "                          \"W\": 16, \"Y\": 17, \"T\": 18, \"V\": 19, \"I\": 20}\n",
    "    \n",
    "    fasta = list(str(data))\n",
    "    # Encode data\n",
    "    for index, value in enumerate(fasta):\n",
    "        fasta[index] = residue_dictionary[value]\n",
    "    # Pad data\n",
    "\n",
    "    # Invert FASTA and make list 200 times the length to avoid edge cases where FASTA is small\n",
    "    padding = fasta[::-1]*2000\n",
    "    \n",
    "    split = int((input_size-len(fasta))/2)\n",
    "    last_padding_len = input_size - len(fasta) - split\n",
    "\n",
    "    stop_pos = int(split+len(fasta))\n",
    "    padding_1 = padding[-split:]\n",
    "    padding_2 = padding[:last_padding_len]\n",
    "    fasta = padding_1 + fasta + padding_2\n",
    "    \n",
    "    # Reshape data for input\n",
    "    fasta = np.array(fasta).reshape(-1, input_size, 1)\n",
    "    # Normalize data by subtracting training mean and dividing by training std. deviation\n",
    "    fasta = (fasta - 10.108613363425793)/6.034641898334733\n",
    "    return fasta, split, stop_pos\n",
    "\n",
    "def afsm3_encode_data(data, input_size):\n",
    "    \"\"\"\n",
    "    Takes in fasta sequence and returns encoded/padded data\n",
    "    \"\"\"\n",
    "    residue_dictionary = {\"A\": 1, \"E\": 2, \"L\": 3, \"M\": 4, \"C\": 5, \"D\": 6, \"F\": 7, \"G\": 8,\n",
    "                          \"H\": 9, \"K\":10, \"N\": 11, \"P\": 12, \"Q\": 13, \"R\": 14, \"S\": 15,\n",
    "                          \"W\": 16, \"Y\": 17, \"T\": 18, \"V\": 19, \"I\": 20}\n",
    "    \n",
    "    fasta = list(str(data))\n",
    "    # Encode data\n",
    "    for index, value in enumerate(fasta):\n",
    "        fasta[index] = residue_dictionary[value]\n",
    "    # Pad data\n",
    "\n",
    "    # Invert FASTA and make list 200 times the length to avoid edge cases where FASTA is small\n",
    "    padding = fasta[::-1]*2000\n",
    "    \n",
    "    split = int((input_size-len(fasta))/2)\n",
    "    last_padding_len = input_size - len(fasta) - split\n",
    "\n",
    "    stop_pos = int(split+len(fasta))\n",
    "    padding_1 = padding[-split:]\n",
    "    padding_2 = padding[:last_padding_len]\n",
    "    fasta = padding_1 + fasta + padding_2\n",
    "    \n",
    "    # Reshape data for input\n",
    "    fasta = np.array(fasta).reshape(-1, input_size, 1)\n",
    "    # Normalize data by subtracting training mean and dividing by training std. deviation\n",
    "    fasta = (fasta - 10.15)/5.98\n",
    "    return fasta, split, stop_pos\n",
    "\n",
    "\n",
    "def afsm12_predict_data(fasta, model, input_size):\n",
    "    \"\"\"\n",
    "    Generate prediction for data point. Will return either predicted pae or plddt.\n",
    "    \"\"\"\n",
    "\n",
    "    data, start_pos, stop_pos = afsm12_encode_data(fasta, input_size)\n",
    "    prediction = model.predict(data).reshape(input_size, 1)\n",
    "    prediction = prediction[start_pos:stop_pos]\n",
    "    prediction = [float(i) for i in prediction]\n",
    "\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def afsm3_predict_data(fasta, model, input_size):\n",
    "    \"\"\"\n",
    "    Generate prediction for data point. Will return either probability of \n",
    "    crystallization.\n",
    "    \"\"\"\n",
    "\n",
    "    data, start_pos, stop_pos = afsm3_encode_data(fasta, input_size)\n",
    "    prediction = model.predict(data)[0]\n",
    "    prediction = list(prediction[:,1])\n",
    "    prediction = prediction[start_pos:stop_pos]\n",
    "    prediction = [float(i) for i in prediction]\n",
    "\n",
    "    return prediction\n",
    "\n",
    "def encode_sequence(fasta):\n",
    "    \n",
    "    residue_dictionary = {\"A\": 1, \"E\": 2, \"L\": 3, \"M\": 4, \"C\": 5, \"D\": 6, \"F\": 7, \"G\": 8,\n",
    "                          \"H\": 9, \"K\":10, \"N\": 11, \"P\": 12, \"Q\": 13, \"R\": 14, \"S\": 15,\n",
    "                          \"W\": 16, \"Y\": 17, \"T\": 18, \"V\": 19, \"I\": 20}\n",
    "    \n",
    "    fasta = list(str(fasta))\n",
    "    # Encode data\n",
    "    for index, value in enumerate(fasta):\n",
    "        fasta[index] = int(residue_dictionary[value])\n",
    "        \n",
    "    return fasta\n",
    "\n",
    "def process_protein(sequence, mae_pred, plddt_pred, presort_pred, ordinal_list, model):\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    win_size = 11\n",
    "    \n",
    "    start, label, stop = 0, int(win_size), int((win_size * 2) + 1)\n",
    "    \n",
    "\n",
    "    while stop < len(sequence)+1:\n",
    "        \n",
    "        prediction = model.predict(mae_pred[start:stop] + plddt_pred[start:stop] + presort_pred[start:stop] + ordinal_list[start:stop])\n",
    "        predictions.append(prediction)\n",
    "        \n",
    "        start += 1\n",
    "        label += 1\n",
    "        stop += 1\n",
    "        \n",
    "    if predictions[0] == 0 and np.mean(np.array(presort_pred[:12])) < 0.7:\n",
    "        \n",
    "        predictions = [0]*win_size + predictions\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        predictions = [1]*win_size + predictions\n",
    "        \n",
    "    if predictions[-1] == 0 and np.mean(np.array(presort_pred[-12:])) < 0.7:\n",
    "        \n",
    "        predictions += [0]*win_size\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        predictions += [1]*win_size\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def disorder_list(sequence: str) -> float:\n",
    "\n",
    "    predictions = []\n",
    "    # generate encodings for sequence\n",
    "    afsm1_pred = afsm12_predict_data(sequence, afsm1_model, 4096)\n",
    "    afsm2_pred = list(np.array(afsm12_predict_data(sequence, afsm2_model, 4096))/100.0)\n",
    "    afsm3_pred = afsm3_predict_data(sequence, afsm3_model, 2048)\n",
    "    ordinal_list = encode_sequence(sequence)\n",
    "    # window size of predictions\n",
    "    win_size = 11\n",
    "\n",
    "    start, label, stop = 0, int(win_size), int((win_size * 2) + 1)\n",
    "\n",
    "    while stop < len(sequence) + 1:\n",
    "        prediction = pirate_model.predict_proba(\n",
    "            afsm1_pred[start:stop] + afsm2_pred[start:stop] + afsm3_pred[start:stop] +\n",
    "        ordinal_list[start:stop])[0]\n",
    "        predictions.append(prediction)\n",
    "\n",
    "        start += 1\n",
    "        label += 1\n",
    "        stop += 1\n",
    "\n",
    "    predictions = [0]*win_size + predictions + [0]*win_size\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b240aec7-2924-4d1c-8ef4-68b19397352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = pathlib.Path().absolute()\n",
    "model_path = str(local_path.parents[0])+\"/models/\"\n",
    "afsm1_path = model_path+\"afsm1\"\n",
    "afsm2_path = model_path+\"afsm2\"\n",
    "afsm3_path = model_path+\"afsm3\"\n",
    "pirate_path = model_path+\"pirate.pkl\"\n",
    "input_size = 4096\n",
    "presort_input = 2048\n",
    "afsm1_model = tf.keras.models.load_model(afsm1_path, custom_objects=None, compile=True, options=None)\n",
    "print(\"afsm1 loaded\")\n",
    "afsm2_model = tf.keras.models.load_model(afsm2_path, custom_objects=None, compile=True, options=None)\n",
    "print(\"afsm2 loaded\")\n",
    "afsm3_model = tf.keras.models.load_model(afsm3_path, custom_objects=None, compile=True, options=None)\n",
    "print(\"afsm3 loaded\")\n",
    "pirate_model = pickle.load(open(pirate_path, 'rb'))\n",
    "print(\"pirate loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b11672-6ec5-473b-b1d7-01e53a7666e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"agt_trypsin_data.csv\")\n",
    "names = data.name.tolist()\n",
    "sequences = data.sequence.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b192396f-92d9-4204-8ff6-a18f5baf6730",
   "metadata": {},
   "outputs": [],
   "source": [
    "pirate_preds = []\n",
    "for count, sequence in enumerate(sequences):\n",
    "    results = disorder_list(sequence)\n",
    "    pirate_preds.append(results)\n",
    "\n",
    "pirate_preds = np.array(pirate_preds)\n",
    "pirate_corrs = []\n",
    "for column in pirate_preds.T:\n",
    "    pirate_corrs.append(spearmanr(column, trypsin_activities)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e56ae31-7d4b-4cb4-ac0b-5b1d6df579b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preds = []\n",
    "for sequence in sequences:\n",
    "    encoded = tokenizer.encode_plus((\"something\", str(sequence)), return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        output = bert_model(**encoded)\n",
    "    output = F.softmax(torch.squeeze(output['logits']))[2:-2,1].detach().numpy().tolist()\n",
    "    bert_preds.append(output)\n",
    "bert_preds = np.array(bert_preds)\n",
    "\n",
    "bert_corrs = []\n",
    "for column in bert_preds.T:\n",
    "    bert_corrs.append(spearmanr(column, trypsin_activities)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b90854f-8a6b-49c9-82be-d3d8b18105fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "caid_corrs = []\n",
    "for model in models:\n",
    "    temp_preds = []\n",
    "    temp_trypsin = []\n",
    "    temp_corrs = []\n",
    "\n",
    "    for count, data in enumerate(datafiles):\n",
    "        try:\n",
    "            temp_file = pd.read_csv(f\"{data}.tsv\", sep=\"\\t\")\n",
    "            temp_preds.append(temp_file[f\"{model}\"].tolist())\n",
    "            temp_trypsin.append(trypsin_activities[count])\n",
    "        except:\n",
    "            continue\n",
    "    temp_preds = np.array(temp_preds)\n",
    "\n",
    "    for column in temp_preds.T:\n",
    "        temp_corrs.append(spearmanr(column, temp_trypsin)[0])\n",
    "    caid_corrs.append(temp_corrs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57521b8-a268-4a09-8716-cd5f8dd3e91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_data = pd.DataFrame()\n",
    "correlation_data[\"PIRATE\"] = pirate_corrs\n",
    "correlation_data[\"DR-BERT\"] = bert_corrs\n",
    "\n",
    "for count, model in enumerate(models):\n",
    "    correlation_data[f\"{model}\"] = caid_corrs[count]\n",
    "\n",
    "correlation_data.to_csv(\"correlation_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
