{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d6733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import json\n",
    "import torch\n",
    "from scipy.stats import spearmanr\n",
    "import catboost\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForTokenClassification\n",
    "import torch.nn.functional as F\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1498cde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def afsm12_encode_data(data, input_size):\n",
    "    \"\"\"\n",
    "    Takes in fasta sequence and returns encoded/padded data\n",
    "    \"\"\"\n",
    "    residue_dictionary = {\"A\": 1, \"E\": 2, \"L\": 3, \"M\": 4, \"C\": 5, \"D\": 6, \"F\": 7, \"G\": 8,\n",
    "                          \"H\": 9, \"K\":10, \"N\": 11, \"P\": 12, \"Q\": 13, \"R\": 14, \"S\": 15,\n",
    "                          \"W\": 16, \"Y\": 17, \"T\": 18, \"V\": 19, \"I\": 20}\n",
    "    \n",
    "    fasta = list(str(data))\n",
    "    # Encode data\n",
    "    for index, value in enumerate(fasta):\n",
    "        fasta[index] = residue_dictionary[value]\n",
    "    # Pad data\n",
    "\n",
    "    # Invert FASTA and make list 200 times the length to avoid edge cases where FASTA is small\n",
    "    padding = fasta[::-1]*2000\n",
    "    \n",
    "    split = int((input_size-len(fasta))/2)\n",
    "    last_padding_len = input_size - len(fasta) - split\n",
    "\n",
    "    stop_pos = int(split+len(fasta))\n",
    "    padding_1 = padding[-split:]\n",
    "    padding_2 = padding[:last_padding_len]\n",
    "    fasta = padding_1 + fasta + padding_2\n",
    "    \n",
    "    # Reshape data for input\n",
    "    fasta = np.array(fasta).reshape(-1, input_size, 1)\n",
    "    # Normalize data by subtracting training mean and dividing by training std. deviation\n",
    "    fasta = (fasta - 10.108613363425793)/6.034641898334733\n",
    "    return fasta, split, stop_pos\n",
    "\n",
    "def afsm3_encode_data(data, input_size):\n",
    "    \"\"\"\n",
    "    Takes in fasta sequence and returns encoded/padded data\n",
    "    \"\"\"\n",
    "    residue_dictionary = {\"A\": 1, \"E\": 2, \"L\": 3, \"M\": 4, \"C\": 5, \"D\": 6, \"F\": 7, \"G\": 8,\n",
    "                          \"H\": 9, \"K\":10, \"N\": 11, \"P\": 12, \"Q\": 13, \"R\": 14, \"S\": 15,\n",
    "                          \"W\": 16, \"Y\": 17, \"T\": 18, \"V\": 19, \"I\": 20}\n",
    "    \n",
    "    fasta = list(str(data))\n",
    "    # Encode data\n",
    "    for index, value in enumerate(fasta):\n",
    "        fasta[index] = residue_dictionary[value]\n",
    "    # Pad data\n",
    "\n",
    "    # Invert FASTA and make list 200 times the length to avoid edge cases where FASTA is small\n",
    "    padding = fasta[::-1]*2000\n",
    "    \n",
    "    split = int((input_size-len(fasta))/2)\n",
    "    last_padding_len = input_size - len(fasta) - split\n",
    "\n",
    "    stop_pos = int(split+len(fasta))\n",
    "    padding_1 = padding[-split:]\n",
    "    padding_2 = padding[:last_padding_len]\n",
    "    fasta = padding_1 + fasta + padding_2\n",
    "    \n",
    "    # Reshape data for input\n",
    "    fasta = np.array(fasta).reshape(-1, input_size, 1)\n",
    "    # Normalize data by subtracting training mean and dividing by training std. deviation\n",
    "    fasta = (fasta - 10.15)/5.98\n",
    "    return fasta, split, stop_pos\n",
    "\n",
    "\n",
    "def afsm12_predict_data(fasta, model, input_size):\n",
    "    \"\"\"\n",
    "    Generate prediction for data point. Will return either predicted pae or plddt.\n",
    "    \"\"\"\n",
    "\n",
    "    data, start_pos, stop_pos = afsm12_encode_data(fasta, input_size)\n",
    "    prediction = model.predict(data).reshape(input_size, 1)\n",
    "    prediction = prediction[start_pos:stop_pos]\n",
    "    prediction = [float(i) for i in prediction]\n",
    "\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def afsm3_predict_data(fasta, model, input_size):\n",
    "    \"\"\"\n",
    "    Generate prediction for data point. Will return either probability of \n",
    "    crystallization.\n",
    "    \"\"\"\n",
    "\n",
    "    data, start_pos, stop_pos = afsm3_encode_data(fasta, input_size)\n",
    "    prediction = model.predict(data)[0]\n",
    "    prediction = list(prediction[:,1])\n",
    "    prediction = prediction[start_pos:stop_pos]\n",
    "    prediction = [float(i) for i in prediction]\n",
    "\n",
    "    return prediction\n",
    "\n",
    "def encode_sequence(fasta):\n",
    "    \n",
    "    residue_dictionary = {\"A\": 1, \"E\": 2, \"L\": 3, \"M\": 4, \"C\": 5, \"D\": 6, \"F\": 7, \"G\": 8,\n",
    "                          \"H\": 9, \"K\":10, \"N\": 11, \"P\": 12, \"Q\": 13, \"R\": 14, \"S\": 15,\n",
    "                          \"W\": 16, \"Y\": 17, \"T\": 18, \"V\": 19, \"I\": 20}\n",
    "    \n",
    "    fasta = list(str(fasta))\n",
    "    # Encode data\n",
    "    for index, value in enumerate(fasta):\n",
    "        fasta[index] = int(residue_dictionary[value])\n",
    "        \n",
    "    return fasta\n",
    "\n",
    "def process_protein(sequence, mae_pred, plddt_pred, presort_pred, ordinal_list, model):\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    win_size = 11\n",
    "    \n",
    "    start, label, stop = 0, int(win_size), int((win_size * 2) + 1)\n",
    "    \n",
    "\n",
    "    while stop < len(sequence)+1:\n",
    "        \n",
    "        prediction = model.predict(mae_pred[start:stop] + plddt_pred[start:stop] + presort_pred[start:stop] + ordinal_list[start:stop])\n",
    "        predictions.append(prediction)\n",
    "        \n",
    "        start += 1\n",
    "        label += 1\n",
    "        stop += 1\n",
    "        \n",
    "    if predictions[0] == 0 and np.mean(np.array(presort_pred[:12])) < 0.7:\n",
    "        \n",
    "        predictions = [0]*win_size + predictions\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        predictions = [1]*win_size + predictions\n",
    "        \n",
    "    if predictions[-1] == 0 and np.mean(np.array(presort_pred[-12:])) < 0.7:\n",
    "        \n",
    "        predictions += [0]*win_size\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        predictions += [1]*win_size\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def disorder_list(sequence: str) -> float:\n",
    "\n",
    "    predictions = []\n",
    "    # generate encodings for sequence\n",
    "    afsm1_pred = afsm12_predict_data(sequence, afsm1_model, 4096)\n",
    "    afsm2_pred = list(np.array(afsm12_predict_data(sequence, afsm2_model, 4096))/100.0)\n",
    "    afsm3_pred = afsm3_predict_data(sequence, afsm3_model, 2048)\n",
    "    ordinal_list = encode_sequence(sequence)\n",
    "    # window size of predictions\n",
    "    win_size = 11\n",
    "\n",
    "    start, label, stop = 0, int(win_size), int((win_size * 2) + 1)\n",
    "\n",
    "    while stop < len(sequence) + 1:\n",
    "        prediction = pirate_model.predict_proba(\n",
    "            afsm1_pred[start:stop] + afsm2_pred[start:stop] + afsm3_pred[start:stop] +\n",
    "        ordinal_list[start:stop])[0]\n",
    "        predictions.append(prediction)\n",
    "\n",
    "        start += 1\n",
    "        label += 1\n",
    "        stop += 1\n",
    "\n",
    "    predictions = [0]*win_size + predictions + [0]*win_size\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b240aec7-2924-4d1c-8ef4-68b19397352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = pathlib.Path().absolute()\n",
    "model_path = str(local_path.parents[0])+\"/models/\"\n",
    "afsm1_path = model_path+\"afsm1\"\n",
    "afsm2_path = model_path+\"afsm2\"\n",
    "afsm3_path = model_path+\"afsm3\"\n",
    "pirate_path = model_path+\"pirate.pkl\"\n",
    "input_size = 4096\n",
    "presort_input = 2048\n",
    "afsm1_model = tf.keras.models.load_model(afsm1_path, custom_objects=None, compile=True, options=None)\n",
    "print(\"afsm1 loaded\")\n",
    "afsm2_model = tf.keras.models.load_model(afsm2_path, custom_objects=None, compile=True, options=None)\n",
    "print(\"afsm2 loaded\")\n",
    "afsm3_model = tf.keras.models.load_model(afsm3_path, custom_objects=None, compile=True, options=None)\n",
    "print(\"afsm3 loaded\")\n",
    "pirate_model = pickle.load(open(pirate_path, 'rb'))\n",
    "print(\"pirate loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb757be-6eac-47af-aa76-da6ae6190c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please change this path to the location of your local DR-BERT checkpoint file\n",
    "checkpoint = r\"C:\\Users\\GRICHARDSON\\OneDrive - Evotec\\Desktop\\crystallization_deletion_tool\\DR-BERT-final\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "bert_model = AutoModelForTokenClassification.from_pretrained(checkpoint)\n",
    "bert_model = bert_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b11672-6ec5-473b-b1d7-01e53a7666e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# >sp|P20711|DDC_HUMAN Aromatic-L-amino-acid decarboxylase OS=Homo sapiens OX=9606 GN=DDC PE=1 SV=2\n",
    "aadc = \"MNASEFRRRGKEMVDYMANYMEGIEGRQVYPDVEPGYLRPLIPAAAPQEPDTFEDIINDVEKIIMPGVTHWHSPYFFAYFPTASSYPAMLADMLCGAIGCIGFSWAASPACTELETVMMDWLGKMLELPKAFLNEKAGEGGGVIQGSASEATLVALLAARTKVIHRLQAASPELTQAAIMEKLVAYSSDQAHSSVERAGLIGGVKLKAIPSDGNFAMRASALQEALERDKAAGLIPFFMVATLGTTTCCSFDNLLEVGPICNKEDIWLHVDAAYAGSAFICPEFRHLLNGVEFADSFNFNPHKWLLVNFDCSAMWVKKRTDLTGAFRLDPTYLKHSHQDSGLITDYRHWQIPLGRRFRSLKMWFVFRMYGVKGLQAYIRKHVQLSHEFESLVRQDPRFEICVEVILGLVCFRLKGSNKVNEALLQRINSAKKIHLVPCHLRDKFVLRFAICSRTVESAHVQRAWEHIKELAADVLRAERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed49593-7e80-4eeb-b487-e29ba8fc3dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# >sp|P68104|EF1A1_HUMAN Elongation factor 1-alpha 1 OS=Homo sapiens OX=9606 GN=EEF1A1 PE=1 SV=1\n",
    "ef1a = \"MGKEKTHINIVVIGHVDSGKSTTTGHLIYKCGGIDKRTIEKFEKEAAEMGKGSFKYAWVLDKLKAERERGITIDISLWKFETSKYYVTIIDAPGHRDFIKNMITGTSQADCAVLIVAAGVGEFEAGISKNGQTREHALLAYTLGVKQLIVGVNKMDSTEPPYSQKRYEEIVKEVSTYIKKIGYNPDTVAFVPISGWNGDNMLEPSANMPWFKGWKVTRKDGNASGTTLLEALDCILPPTRPTDKPLRLPLQDVYKIGGIGTVPVGRVETGVLKPGMVVTFAPVNVTTEVKSVEMHHEALSEALPGDNVGFNVKNVSVKDVRRGNVAGDSKNDPPMEAAGFTAQVIILNHPGQISAGYAPVLDCHTAHIACKFAELKEKIDRRSGKKLEDGPKFLKSGDAAIVDMVPGKPMCVESFSDYPPLGRFAVRDMRQTVAVGVIKAVDKKAAGAGKVTKSAQKAQKAK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4b0921-d1c4-4023-af44-9d18544a9661",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [aadc, ef1a]\n",
    "sequence_ids = [\"aadc\", \"ef1a\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d646318b-1b40-4b3f-b615-5a58a59d89ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pirate_list = []\n",
    "for sequence in sequences:\n",
    "    pirate_list.append(disorder_list(sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32352db8-ab98-4bf3-bc39-097cc7c7e65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_list = []\n",
    "for sequence in sequences:\n",
    "    encoded = tokenizer.encode_plus((\"something\", str(sequence)), return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        output = bert_model(**encoded)\n",
    "    output = F.softmax(torch.squeeze(output['logits']))[2:-2,1].detach().numpy().tolist()\n",
    "    bert_list.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ed09c5-7f25-443e-b19c-4e6f68555444",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "data[\"sequence_ids\"] = sequence_ids\n",
    "data[\"pirate_preds\"] = pirate_list\n",
    "data[\"dr_bert_preds\"] = bert_list\n",
    "\n",
    "data.to_csv(\"aadc_efa1_preds_pirate_bert.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b192396f-92d9-4204-8ff6-a18f5baf6730",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
