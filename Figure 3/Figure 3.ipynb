{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d6733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, precision_score, auc, make_scorer, recall_score, matthews_corrcoef, f1_score, balanced_accuracy_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1498cde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def afsm12_encode_data(data, input_size):\n",
    "    \"\"\"\n",
    "    Takes in fasta sequence and returns encoded/padded data\n",
    "    \"\"\"\n",
    "    residue_dictionary = {\"A\": 1, \"E\": 2, \"L\": 3, \"M\": 4, \"C\": 5, \"D\": 6, \"F\": 7, \"G\": 8,\n",
    "                          \"H\": 9, \"K\":10, \"N\": 11, \"P\": 12, \"Q\": 13, \"R\": 14, \"S\": 15,\n",
    "                          \"W\": 16, \"Y\": 17, \"T\": 18, \"V\": 19, \"I\": 20}\n",
    "    \n",
    "    fasta = list(str(data))\n",
    "    # Encode data\n",
    "    for index, value in enumerate(fasta):\n",
    "        fasta[index] = residue_dictionary[value]\n",
    "    # Pad data\n",
    "\n",
    "    # Invert FASTA and make list 200 times the length to avoid edge cases where FASTA is small\n",
    "    padding = fasta[::-1]*2000\n",
    "    \n",
    "    split = int((input_size-len(fasta))/2)\n",
    "    last_padding_len = input_size - len(fasta) - split\n",
    "\n",
    "    stop_pos = int(split+len(fasta))\n",
    "    padding_1 = padding[-split:]\n",
    "    padding_2 = padding[:last_padding_len]\n",
    "    fasta = padding_1 + fasta + padding_2\n",
    "    \n",
    "    # Reshape data for input\n",
    "    fasta = np.array(fasta).reshape(-1, input_size, 1)\n",
    "    # Normalize data by subtracting training mean and dividing by training std. deviation\n",
    "    fasta = (fasta - 10.108613363425793)/6.034641898334733\n",
    "    return fasta, split, stop_pos\n",
    "\n",
    "def afsm3_encode_data(data, input_size):\n",
    "    \"\"\"\n",
    "    Takes in fasta sequence and returns encoded/padded data\n",
    "    \"\"\"\n",
    "    residue_dictionary = {\"A\": 1, \"E\": 2, \"L\": 3, \"M\": 4, \"C\": 5, \"D\": 6, \"F\": 7, \"G\": 8,\n",
    "                          \"H\": 9, \"K\":10, \"N\": 11, \"P\": 12, \"Q\": 13, \"R\": 14, \"S\": 15,\n",
    "                          \"W\": 16, \"Y\": 17, \"T\": 18, \"V\": 19, \"I\": 20}\n",
    "    \n",
    "    fasta = list(str(data))\n",
    "    # Encode data\n",
    "    for index, value in enumerate(fasta):\n",
    "        fasta[index] = residue_dictionary[value]\n",
    "    # Pad data\n",
    "\n",
    "    # Invert FASTA and make list 200 times the length to avoid edge cases where FASTA is small\n",
    "    padding = fasta[::-1]*2000\n",
    "    \n",
    "    split = int((input_size-len(fasta))/2)\n",
    "    last_padding_len = input_size - len(fasta) - split\n",
    "\n",
    "    stop_pos = int(split+len(fasta))\n",
    "    padding_1 = padding[-split:]\n",
    "    padding_2 = padding[:last_padding_len]\n",
    "    fasta = padding_1 + fasta + padding_2\n",
    "    \n",
    "    # Reshape data for input\n",
    "    fasta = np.array(fasta).reshape(-1, input_size, 1)\n",
    "    # Normalize data by subtracting training mean and dividing by training std. deviation\n",
    "    fasta = (fasta - 10.15)/5.98\n",
    "    return fasta, split, stop_pos\n",
    "\n",
    "\n",
    "def afsm12_predict_data(fasta, model, input_size):\n",
    "    \"\"\"\n",
    "    Generate prediction for data point. Will return either predicted pae or plddt.\n",
    "    \"\"\"\n",
    "\n",
    "    data, start_pos, stop_pos = afsm12_encode_data(fasta, input_size)\n",
    "    prediction = model.predict(data).reshape(input_size, 1)\n",
    "    prediction = prediction[start_pos:stop_pos]\n",
    "    prediction = [float(i) for i in prediction]\n",
    "\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def afsm3_predict_data(fasta, model, input_size):\n",
    "    \"\"\"\n",
    "    Generate prediction for data point. Will return either probability of \n",
    "    crystallization.\n",
    "    \"\"\"\n",
    "\n",
    "    data, start_pos, stop_pos = afsm3_encode_data(fasta, input_size)\n",
    "    prediction = model.predict(data)[0]\n",
    "    prediction = list(prediction[:,1])\n",
    "    prediction = prediction[start_pos:stop_pos]\n",
    "    prediction = [float(i) for i in prediction]\n",
    "\n",
    "    return prediction\n",
    "\n",
    "def encode_sequence(fasta):\n",
    "    \n",
    "    residue_dictionary = {\"A\": 1, \"E\": 2, \"L\": 3, \"M\": 4, \"C\": 5, \"D\": 6, \"F\": 7, \"G\": 8,\n",
    "                          \"H\": 9, \"K\":10, \"N\": 11, \"P\": 12, \"Q\": 13, \"R\": 14, \"S\": 15,\n",
    "                          \"W\": 16, \"Y\": 17, \"T\": 18, \"V\": 19, \"I\": 20}\n",
    "    \n",
    "    fasta = list(str(fasta))\n",
    "    # Encode data\n",
    "    for index, value in enumerate(fasta):\n",
    "        fasta[index] = int(residue_dictionary[value])\n",
    "        \n",
    "    return fasta\n",
    "\n",
    "def disorder_list(sequence: str) -> float:\n",
    "\n",
    "    predictions = []\n",
    "    # generate encodings for sequence\n",
    "    afsm1_pred = afsm12_predict_data(sequence, afsm1_model, 4096)\n",
    "    afsm2_pred = list(np.array(afsm12_predict_data(sequence, afsm2_model, 4096))/100.0)\n",
    "    afsm3_pred = afsm3_predict_data(sequence, afsm3_model, 2048)\n",
    "    ordinal_list = encode_sequence(sequence)\n",
    "    # window size of predictions\n",
    "    win_size = 11\n",
    "\n",
    "    start, label, stop = 0, int(win_size), int((win_size * 2) + 1)\n",
    "\n",
    "    while stop < len(sequence) + 1:\n",
    "        prediction = pirate_model.predict_proba(\n",
    "            afsm1_pred[start:stop] + afsm2_pred[start:stop] + afsm3_pred[start:stop] +\n",
    "        ordinal_list[start:stop])[0]\n",
    "        predictions.append(prediction)\n",
    "\n",
    "        start += 1\n",
    "        label += 1\n",
    "        stop += 1\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89309fad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "local_path = pathlib.Path().absolute()\n",
    "model_path = str(local_path.parents[0])+\"/models/\"\n",
    "afsm1_path = model_path+\"afsm1\"\n",
    "afsm2_path = model_path+\"afsm2\"\n",
    "afsm3_path = model_path+\"afsm3\"\n",
    "pirate_path = model_path+\"pirate.pkl\"\n",
    "input_size = 4096\n",
    "presort_input = 2048\n",
    "afsm1_model = tf.keras.models.load_model(afsm1_path, custom_objects=None, compile=True, options=None)\n",
    "print(\"afsm1 loaded\")\n",
    "afsm2_model = tf.keras.models.load_model(afsm2_path, custom_objects=None, compile=True, options=None)\n",
    "print(\"afsm2 loaded\")\n",
    "afsm3_model = tf.keras.models.load_model(afsm3_path, custom_objects=None, compile=True, options=None)\n",
    "print(\"afsm3 loaded\")\n",
    "pirate_model = pickle.load(open(pirate_path, 'rb'))\n",
    "print(\"pirate loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ae0d47-8fa6-450c-8169-b4fcdf549d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "labels = []\n",
    "features = []\n",
    "\n",
    "file = open('disorder_pdb.fasta','r')\n",
    "count = 0\n",
    "for line in file:\n",
    "    line = line.replace('\\n', ' ').replace('\\r', '').replace('>', '')\n",
    "    if count == 0:\n",
    "        ids.append(line.strip())\n",
    "    if count == 1:\n",
    "        features.append(line.strip())\n",
    "    if count == 2:\n",
    "        line = line.strip()\n",
    "        line = [e for e in line]\n",
    "        labels.append(line)\n",
    "        count = 0\n",
    "        continue\n",
    "    count += 1\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736ed1ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "probs = []\n",
    "ground_truth = []\n",
    "\n",
    "for count, sequence in enumerate(features):\n",
    "    \n",
    "    if len(sequence) < 2048:\n",
    "        \n",
    "        afsm1_pred = afsm12_predict_data(sequence, afsm1_model, 4096)\n",
    "        afsm2_pred = list(np.array(afsm12_predict_data(sequence, afsm2_model, 4096))/100.0)\n",
    "        afsm3_pred = afsm3_predict_data(sequence, afsm3_model, 2048)\n",
    "        ordinal_list = encode_sequence(sequence)\n",
    "        probabilities = disorder_list(sequence)      \n",
    "        probs += probabilities\n",
    "        ground_truth += labels[count][11:-11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b782794-caa1-4910-aafa-151f68a0a750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove labels and corresponding predictions if the label isn't 1 or 0\n",
    "for count, value in reversed(list(enumerate(ground_truth))):\n",
    "    if value == \"-\":\n",
    "        del ground_truth[count]\n",
    "        del probs[count]\n",
    "\n",
    "for count, e in enumerate(ground_truth):\n",
    "    ground_truth[count] = int(ground_truth[count])\n",
    "    probs[count] = float(probs[count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8107731",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f1 = 0.0\n",
    "best_threshold = 0\n",
    "best_preds = []\n",
    "for threshold in range(1, 1000, 1):\n",
    "    new_preds = []\n",
    "    threshold = float(threshold/1000.0)\n",
    "    for count, prob in enumerate(probs):\n",
    "        if prob >= threshold:\n",
    "            new_preds.append(1)\n",
    "        if prob < threshold:\n",
    "            new_preds.append(0)\n",
    "            \n",
    "    f1 = f1_score(ground_truth, new_preds)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "        best_preds = new_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60016813",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy = balanced_accuracy_score(ground_truth, best_preds)\n",
    "f1 = f1_score(ground_truth, best_preds)\n",
    "mcc = matthews_corrcoef(ground_truth, best_preds)\n",
    "auc = roc_auc_score(ground_truth, probs)\n",
    "aps = average_precision_score(ground_truth, probs)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 max: {f1}\")\n",
    "print(f\"MCC: {mcc}\")\n",
    "print(f\"AUC: {auc}\")\n",
    "print(f\"APS: {aps}\")\n",
    "print(classification_report(ground_truth, best_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418816ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
