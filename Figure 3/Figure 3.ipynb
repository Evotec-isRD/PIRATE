{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9d6733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, precision_score, auc, make_scorer, recall_score, matthews_corrcoef, f1_score, balanced_accuracy_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1498cde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def afsm12_encode_data(data, input_size):\n",
    "    \"\"\"\n",
    "    Takes in fasta sequence and returns encoded/padded data\n",
    "    \"\"\"\n",
    "    residue_dictionary = {\"A\": 1, \"E\": 2, \"L\": 3, \"M\": 4, \"C\": 5, \"D\": 6, \"F\": 7, \"G\": 8,\n",
    "                          \"H\": 9, \"K\":10, \"N\": 11, \"P\": 12, \"Q\": 13, \"R\": 14, \"S\": 15,\n",
    "                          \"W\": 16, \"Y\": 17, \"T\": 18, \"V\": 19, \"I\": 20}\n",
    "    \n",
    "    fasta = list(str(data))\n",
    "    # Encode data\n",
    "    for index, value in enumerate(fasta):\n",
    "        fasta[index] = residue_dictionary[value]\n",
    "    # Pad data\n",
    "\n",
    "    # Invert FASTA and make list 200 times the length to avoid edge cases where FASTA is small\n",
    "    padding = fasta[::-1]*2000\n",
    "    \n",
    "    split = int((input_size-len(fasta))/2)\n",
    "    last_padding_len = input_size - len(fasta) - split\n",
    "\n",
    "    stop_pos = int(split+len(fasta))\n",
    "    padding_1 = padding[-split:]\n",
    "    padding_2 = padding[:last_padding_len]\n",
    "    fasta = padding_1 + fasta + padding_2\n",
    "    \n",
    "    # Reshape data for input\n",
    "    fasta = np.array(fasta).reshape(-1, input_size, 1)\n",
    "    # Normalize data by subtracting training mean and dividing by training std. deviation\n",
    "    fasta = (fasta - 10.108613363425793)/6.034641898334733\n",
    "    return fasta, split, stop_pos\n",
    "\n",
    "def afsm3_encode_data(data, input_size):\n",
    "    \"\"\"\n",
    "    Takes in fasta sequence and returns encoded/padded data\n",
    "    \"\"\"\n",
    "    residue_dictionary = {\"A\": 1, \"E\": 2, \"L\": 3, \"M\": 4, \"C\": 5, \"D\": 6, \"F\": 7, \"G\": 8,\n",
    "                          \"H\": 9, \"K\":10, \"N\": 11, \"P\": 12, \"Q\": 13, \"R\": 14, \"S\": 15,\n",
    "                          \"W\": 16, \"Y\": 17, \"T\": 18, \"V\": 19, \"I\": 20}\n",
    "    \n",
    "    fasta = list(str(data))\n",
    "    # Encode data\n",
    "    for index, value in enumerate(fasta):\n",
    "        fasta[index] = residue_dictionary[value]\n",
    "    # Pad data\n",
    "\n",
    "    # Invert FASTA and make list 200 times the length to avoid edge cases where FASTA is small\n",
    "    padding = fasta[::-1]*2000\n",
    "    \n",
    "    split = int((input_size-len(fasta))/2)\n",
    "    last_padding_len = input_size - len(fasta) - split\n",
    "\n",
    "    stop_pos = int(split+len(fasta))\n",
    "    padding_1 = padding[-split:]\n",
    "    padding_2 = padding[:last_padding_len]\n",
    "    fasta = padding_1 + fasta + padding_2\n",
    "    \n",
    "    # Reshape data for input\n",
    "    fasta = np.array(fasta).reshape(-1, input_size, 1)\n",
    "    # Normalize data by subtracting training mean and dividing by training std. deviation\n",
    "    fasta = (fasta - 10.15)/5.98\n",
    "    return fasta, split, stop_pos\n",
    "\n",
    "\n",
    "def afsm12_predict_data(fasta, model, input_size):\n",
    "    \"\"\"\n",
    "    Generate prediction for data point. Will return either predicted pae or plddt.\n",
    "    \"\"\"\n",
    "\n",
    "    data, start_pos, stop_pos = afsm12_encode_data(fasta, input_size)\n",
    "    prediction = model.predict(data).reshape(input_size, 1)\n",
    "    prediction = prediction[start_pos:stop_pos]\n",
    "    prediction = [float(i) for i in prediction]\n",
    "\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def afsm3_predict_data(fasta, model, input_size):\n",
    "    \"\"\"\n",
    "    Generate prediction for data point. Will return either probability of \n",
    "    crystallization.\n",
    "    \"\"\"\n",
    "\n",
    "    data, start_pos, stop_pos = afsm3_encode_data(fasta, input_size)\n",
    "    prediction = model.predict(data)[0]\n",
    "    prediction = list(prediction[:,1])\n",
    "    prediction = prediction[start_pos:stop_pos]\n",
    "    prediction = [float(i) for i in prediction]\n",
    "\n",
    "    return prediction\n",
    "\n",
    "def encode_sequence(fasta):\n",
    "    \n",
    "    residue_dictionary = {\"A\": 1, \"E\": 2, \"L\": 3, \"M\": 4, \"C\": 5, \"D\": 6, \"F\": 7, \"G\": 8,\n",
    "                          \"H\": 9, \"K\":10, \"N\": 11, \"P\": 12, \"Q\": 13, \"R\": 14, \"S\": 15,\n",
    "                          \"W\": 16, \"Y\": 17, \"T\": 18, \"V\": 19, \"I\": 20}\n",
    "    \n",
    "    fasta = list(str(fasta))\n",
    "    # Encode data\n",
    "    for index, value in enumerate(fasta):\n",
    "        fasta[index] = int(residue_dictionary[value])\n",
    "        \n",
    "    return fasta\n",
    "\n",
    "def disorder_list(sequence: str) -> float:\n",
    "\n",
    "    predictions = []\n",
    "    # generate encodings for sequence\n",
    "    afsm1_pred = afsm12_predict_data(sequence, afsm1_model, 4096)\n",
    "    afsm2_pred = list(np.array(afsm12_predict_data(sequence, afsm2_model, 4096))/100.0)\n",
    "    afsm3_pred = afsm3_predict_data(sequence, afsm3_model, 2048)\n",
    "    ordinal_list = encode_sequence(sequence)\n",
    "    # window size of predictions\n",
    "    win_size = 11\n",
    "\n",
    "    start, label, stop = 0, int(win_size), int((win_size * 2) + 1)\n",
    "\n",
    "    while stop < len(sequence) + 1:\n",
    "        prediction = pirate_model.predict_proba(\n",
    "            afsm1_pred[start:stop] + afsm2_pred[start:stop] + afsm3_pred[start:stop] +\n",
    "        ordinal_list[start:stop])[0]\n",
    "        predictions.append(prediction)\n",
    "\n",
    "        start += 1\n",
    "        label += 1\n",
    "        stop += 1\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89309fad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "afsm1 loaded\n",
      "afsm2 loaded\n",
      "afsm3 loaded\n",
      "pirate loaded\n"
     ]
    }
   ],
   "source": [
    "local_path = pathlib.Path().absolute()\n",
    "model_path = str(local_path.parents[0])+\"/models/\"\n",
    "afsm1_path = model_path+\"afsm1\"\n",
    "afsm2_path = model_path+\"afsm2\"\n",
    "afsm3_path = model_path+\"afsm3\"\n",
    "pirate_path = model_path+\"pirate.pkl\"\n",
    "input_size = 4096\n",
    "presort_input = 2048\n",
    "afsm1_model = tf.keras.models.load_model(afsm1_path, custom_objects=None, compile=True, options=None)\n",
    "print(\"afsm1 loaded\")\n",
    "afsm2_model = tf.keras.models.load_model(afsm2_path, custom_objects=None, compile=True, options=None)\n",
    "print(\"afsm2 loaded\")\n",
    "afsm3_model = tf.keras.models.load_model(afsm3_path, custom_objects=None, compile=True, options=None)\n",
    "print(\"afsm3 loaded\")\n",
    "pirate_model = pickle.load(open(pirate_path, 'rb'))\n",
    "print(\"pirate loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44ae0d47-8fa6-450c-8169-b4fcdf549d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348 348 348\n"
     ]
    }
   ],
   "source": [
    "ids = []\n",
    "labels = []\n",
    "features = []\n",
    "\n",
    "file = open('disorder_pdb.fasta','r')\n",
    "count = 0\n",
    "for line in file:\n",
    "    line = line.replace('\\n', ' ').replace('\\r', '').replace('>', '')\n",
    "    if count == 0:\n",
    "        ids.append(line.strip())\n",
    "    if count == 1:\n",
    "        features.append(line.strip())\n",
    "    if count == 2:\n",
    "        line = line.strip()\n",
    "        line = [e for e in line]\n",
    "        labels.append(line)\n",
    "        count = 0\n",
    "        continue\n",
    "    count += 1\n",
    "    continue\n",
    "\n",
    "print(len(ids), len(features), len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "736ed1ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GRICHARDSON\\AppData\\Local\\Temp\\ipykernel_10696\\1885449952.py:72: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  prediction = [float(i) for i in prediction]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 205 205\n",
      "1 393 393\n",
      "2 435 435\n",
      "3 477 477\n",
      "4 1708 1708\n",
      "5 1619 1619\n",
      "6 1836 1836\n",
      "7 1644 1644\n",
      "8 549 549\n",
      "9 741 741\n",
      "10 1220 1220\n",
      "11 527 527\n",
      "12 831 831\n",
      "13 812 812\n",
      "14 379 379\n",
      "15 319 319\n",
      "16 577 577\n",
      "17 742 742\n",
      "18 584 584\n",
      "19 670 670\n",
      "20 551 551\n",
      "21 372 372\n",
      "22 856 856\n",
      "23 1752 1752\n",
      "24 252 252\n",
      "25 350 350\n",
      "26 720 720\n",
      "27 320 320\n",
      "28 395 395\n",
      "29 564 564\n",
      "30 425 425\n",
      "31 894 894\n",
      "33 1082 1082\n",
      "34 569 569\n",
      "35 392 392\n",
      "36 1028 1028\n",
      "37 1236 1236\n",
      "38 568 568\n",
      "39 1827 1827\n",
      "41 1688 1688\n",
      "42 1452 1452\n",
      "43 562 562\n",
      "45 206 206\n",
      "46 393 393\n",
      "47 1704 1704\n",
      "48 589 589\n",
      "49 1808 1808\n",
      "50 477 477\n",
      "51 876 876\n",
      "52 498 498\n",
      "53 672 672\n",
      "54 941 941\n",
      "55 1662 1662\n",
      "56 582 582\n",
      "57 853 853\n",
      "58 795 795\n",
      "59 723 723\n",
      "60 558 558\n",
      "61 576 576\n",
      "62 655 655\n",
      "63 1637 1637\n",
      "64 411 411\n",
      "65 959 959\n",
      "66 1764 1764\n",
      "67 1726 1726\n",
      "68 611 611\n",
      "69 1464 1464\n",
      "70 1110 1110\n",
      "71 263 263\n",
      "72 272 272\n",
      "73 1482 1482\n",
      "74 683 683\n",
      "75 1446 1446\n",
      "76 176 176\n",
      "77 818 818\n",
      "79 306 306\n",
      "80 297 297\n",
      "81 838 838\n",
      "82 460 460\n",
      "83 671 671\n",
      "84 1647 1647\n",
      "85 327 327\n",
      "87 617 617\n",
      "88 257 257\n",
      "89 907 907\n",
      "90 1091 1091\n",
      "91 88 88\n",
      "92 687 687\n",
      "93 161 161\n",
      "94 434 434\n",
      "95 46 46\n",
      "96 1690 1690\n",
      "97 1124 1124\n",
      "98 168 168\n",
      "99 1015 1015\n",
      "100 295 295\n",
      "101 901 901\n",
      "103 743 743\n",
      "104 305 305\n",
      "105 847 847\n",
      "106 434 434\n",
      "107 435 435\n",
      "108 875 875\n",
      "109 1100 1100\n",
      "110 1289 1289\n",
      "111 153 153\n",
      "112 857 857\n",
      "113 604 604\n",
      "114 987 987\n",
      "115 652 652\n",
      "116 1883 1883\n",
      "117 443 443\n",
      "118 802 802\n",
      "119 925 925\n",
      "120 733 733\n",
      "121 498 498\n",
      "122 161 161\n",
      "123 46 46\n",
      "124 1301 1301\n",
      "125 718 718\n",
      "126 509 509\n",
      "127 483 483\n",
      "128 369 369\n",
      "129 972 972\n",
      "131 289 289\n",
      "132 159 159\n",
      "133 645 645\n",
      "135 972 972\n",
      "136 821 821\n",
      "137 1277 1277\n",
      "138 1280 1280\n",
      "139 1021 1021\n",
      "140 1316 1316\n",
      "141 1397 1397\n",
      "142 506 506\n",
      "143 351 351\n",
      "144 227 227\n",
      "145 271 271\n",
      "146 937 937\n",
      "147 455 455\n",
      "148 472 472\n",
      "150 1036 1036\n",
      "151 163 163\n",
      "152 448 448\n",
      "153 1204 1204\n",
      "154 518 518\n",
      "156 663 663\n",
      "157 1468 1468\n",
      "159 512 512\n",
      "160 974 974\n",
      "161 1979 1979\n",
      "162 821 821\n",
      "163 752 752\n",
      "165 817 817\n",
      "167 1475 1475\n",
      "168 712 712\n",
      "169 491 491\n",
      "170 905 905\n",
      "171 342 342\n",
      "172 537 537\n",
      "173 366 366\n",
      "174 81 81\n",
      "175 481 481\n",
      "176 350 350\n",
      "177 80 80\n",
      "178 601 601\n",
      "179 1699 1699\n",
      "180 53 53\n",
      "181 235 235\n",
      "182 1734 1734\n",
      "183 1004 1004\n",
      "184 158 158\n",
      "185 90 90\n",
      "186 74 74\n",
      "187 80 80\n",
      "188 109 109\n",
      "190 754 754\n",
      "191 190 190\n",
      "192 1600 1600\n",
      "193 601 601\n",
      "194 159 159\n",
      "195 433 433\n",
      "196 398 398\n",
      "197 603 603\n",
      "198 127 127\n",
      "199 319 319\n",
      "200 1276 1276\n",
      "201 435 435\n",
      "203 518 518\n",
      "204 1177 1177\n",
      "205 882 882\n",
      "206 579 579\n",
      "207 351 351\n",
      "208 479 479\n",
      "209 3 3\n",
      "210 325 325\n",
      "211 395 395\n",
      "212 1890 1890\n",
      "214 461 461\n",
      "216 288 288\n",
      "217 179 179\n",
      "218 420 420\n",
      "219 131 131\n",
      "220 1107 1107\n",
      "225 941 941\n",
      "226 824 824\n",
      "228 694 694\n",
      "229 694 694\n",
      "230 392 392\n",
      "231 182 182\n",
      "232 1807 1807\n",
      "233 500 500\n",
      "234 133 133\n",
      "235 333 333\n",
      "236 220 220\n",
      "237 238 238\n",
      "238 495 495\n",
      "239 315 315\n",
      "240 753 753\n",
      "241 337 337\n",
      "242 288 288\n",
      "243 456 456\n",
      "244 1215 1215\n",
      "245 275 275\n",
      "246 436 436\n",
      "247 233 233\n",
      "248 715 715\n",
      "249 298 298\n",
      "250 594 594\n",
      "251 289 289\n",
      "252 258 258\n",
      "253 242 242\n",
      "254 329 329\n",
      "255 114 114\n",
      "256 95 95\n",
      "257 402 402\n",
      "258 736 736\n",
      "259 188 188\n",
      "260 213 213\n",
      "261 169 169\n",
      "262 129 129\n",
      "263 123 123\n",
      "264 265 265\n",
      "265 1061 1061\n",
      "266 80 80\n",
      "267 313 313\n",
      "268 464 464\n",
      "269 196 196\n",
      "271 919 919\n",
      "272 1619 1619\n",
      "273 1621 1621\n",
      "274 1379 1379\n",
      "275 1034 1034\n",
      "276 625 625\n",
      "277 894 894\n",
      "278 281 281\n",
      "279 269 269\n",
      "280 372 372\n",
      "281 335 335\n",
      "282 88 88\n",
      "283 386 386\n",
      "284 209 209\n",
      "285 483 483\n",
      "286 890 890\n",
      "287 347 347\n",
      "288 853 853\n",
      "289 911 911\n",
      "290 1056 1056\n",
      "291 586 586\n",
      "292 134 134\n",
      "293 97 97\n",
      "294 372 372\n",
      "295 143 143\n",
      "296 203 203\n",
      "297 60 60\n",
      "298 223 223\n",
      "299 313 313\n",
      "300 114 114\n",
      "301 415 415\n",
      "302 355 355\n",
      "303 337 337\n",
      "304 65 65\n",
      "305 426 426\n",
      "306 530 530\n",
      "307 428 428\n",
      "308 1290 1290\n",
      "309 152 152\n",
      "310 830 830\n",
      "311 181 181\n",
      "312 333 333\n",
      "313 349 349\n",
      "314 344 344\n",
      "315 391 391\n",
      "316 213 213\n",
      "317 934 934\n",
      "318 207 207\n",
      "319 42 42\n",
      "320 136 136\n",
      "321 849 849\n",
      "322 830 830\n",
      "323 648 648\n",
      "324 86 86\n",
      "325 53 53\n",
      "326 672 672\n",
      "327 365 365\n",
      "328 544 544\n",
      "329 553 553\n",
      "330 236 236\n",
      "331 119 119\n",
      "332 46 46\n",
      "333 39 39\n",
      "334 741 741\n",
      "335 817 817\n",
      "336 742 742\n",
      "337 768 768\n",
      "338 674 674\n",
      "339 662 662\n",
      "340 205 205\n",
      "341 405 405\n",
      "342 600 600\n",
      "344 1442 1442\n",
      "345 1469 1469\n",
      "346 156 156\n",
      "347 1262 1262\n"
     ]
    }
   ],
   "source": [
    "probs = []\n",
    "ground_truth = []\n",
    "\n",
    "for count, sequence in enumerate(features):\n",
    "    \n",
    "    if len(sequence) < 2048:\n",
    "        \n",
    "        afsm1_pred = afsm12_predict_data(sequence, afsm1_model, 4096)\n",
    "        afsm2_pred = list(np.array(afsm12_predict_data(sequence, afsm2_model, 4096))/100.0)\n",
    "        afsm3_pred = afsm3_predict_data(sequence, afsm3_model, 2048)\n",
    "        ordinal_list = encode_sequence(sequence)\n",
    "\n",
    "        probabilities = disorder_list(sequence)\n",
    "        \n",
    "        probs += probabilities\n",
    "\n",
    "        ground_truth += labels[count][11:-11]\n",
    "        print(count, len(probabilities), len(labels[count][11:-11]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b782794-caa1-4910-aafa-151f68a0a750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove labels and corresponding predictions if the label isn't 1 or 0\n",
    "for count, value in reversed(list(enumerate(ground_truth))):\n",
    "    if value == \"-\":\n",
    "        del ground_truth[count]\n",
    "        del probs[count]\n",
    "\n",
    "for count, e in enumerate(ground_truth):\n",
    "    ground_truth[count] = int(ground_truth[count])\n",
    "    probs[count] = float(probs[count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8107731",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f1 = 0.0\n",
    "best_threshold = 0\n",
    "best_preds = []\n",
    "for threshold in range(1, 1000, 1):\n",
    "    new_preds = []\n",
    "    threshold = float(threshold/1000.0)\n",
    "    for count, prob in enumerate(probs):\n",
    "        if prob >= threshold:\n",
    "            new_preds.append(1)\n",
    "        if prob < threshold:\n",
    "            new_preds.append(0)\n",
    "            \n",
    "    f1 = f1_score(ground_truth, new_preds)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "        best_preds = new_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60016813",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87427600003662\n",
      "Fmax: 0.8371832069634355\n",
      "MCC: 0.7698086021847229\n",
      "AUC: 0.9332776663191936\n",
      "APS: 0.9059162567355865\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     71579\n",
      "           1       0.88      0.80      0.84     32713\n",
      "\n",
      "    accuracy                           0.90    104292\n",
      "   macro avg       0.90      0.87      0.88    104292\n",
      "weighted avg       0.90      0.90      0.90    104292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = balanced_accuracy_score(ground_truth, best_preds)\n",
    "f1 = f1_score(ground_truth, best_preds)\n",
    "mcc = matthews_corrcoef(ground_truth, best_preds)\n",
    "auc = roc_auc_score(ground_truth, probs)\n",
    "aps = average_precision_score(ground_truth, probs)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Fmax: {f1}\")\n",
    "print(f\"MCC: {mcc}\")\n",
    "print(f\"AUC: {auc}\")\n",
    "print(f\"APS: {aps}\")\n",
    "print(classification_report(ground_truth, best_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418816ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
